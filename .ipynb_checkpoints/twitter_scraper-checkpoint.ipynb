{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('twitter_key.txt', 'r') as file:\n",
    "    KEY = file.read().rstrip()\n",
    "\n",
    "with open('twitter_secret.txt', 'r') as file:\n",
    "    SECRET = file.read().rstrip()\n",
    "\n",
    "with open('twitter_bearer.txt', 'r') as file:\n",
    "    BEARER = file.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweepy auth stuff\n",
    "client = tweepy.Client(BEARER)\n",
    "api = tweepy.API(client, wait_on_rate_limit=True)\n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "    sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.search_recent_tweets('politics', max_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries\n",
    "To query tweets from specific topics, we want to build a query set according to the following tweet context format: `context:domain_id.entity_id`\n",
    "\n",
    "We can check the domain here: https://developer.twitter.com/en/docs/twitter-api/annotations/overview\n",
    "\n",
    "Entity id may be too specfic for our use case. Thus, we can query via: `context:domain_id.*`\n",
    "\n",
    "Below mapping is a list of domain_ids to start with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    clean_tweet = re.sub(\"@[A-Za-z0-9_]+\",\"\", tweet)\n",
    "    clean_tweet = re.sub('http[^\\s]+','',clean_tweet)\n",
    "    return re.sub(\"#[A-Za-z0-9_]+\",\"\", clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = 10\n",
    "domains = {\n",
    "    'TV Shows': 3,\n",
    "    'Sport': 11,\n",
    "    'Politicians': 35,\n",
    "    'Political Race': 38,\n",
    "    'Brand': 47,\n",
    "    'Song': 132,\n",
    "    'Fan Community': 139\n",
    "}\n",
    "for d, c in domains.items():\n",
    "    q = 'context:'+str(c)+'.* AND context:'+str(person)+'.*' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 10\n",
    "curs = tweepy.Cursor(api.search_30_day, label='research', query='context:35.*' , tweet_mode = \"extended\").items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in curs:\n",
    "    print(clean_tweet(i.full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cbc473f91a4c1717b88e811a3ffc9d837a7bf95d812003545246e5cb9a87907"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
